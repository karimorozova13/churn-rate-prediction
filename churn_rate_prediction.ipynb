{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87221,"databundleVersionId":9915830,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import matthews_corrcoef\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.utils.validation import check_is_fitted\n\n# Load the data\nX_train = pd.read_csv(f'{BASE_URL}/train.csv')\nX_test = pd.read_csv(f'{BASE_URL}/test.csv')\n\n# Target column (assuming it's in your train data)\ny = X_train['target_class']\nX_train = X_train.drop('target_class', axis=1)\n\n# Train-test split\nX_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y, test_size=0.2, random_state=42)\n\n# 1. Define the PyTorch Model (Neural Network)\nclass ChurnNet(nn.Module):\n    def __init__(self, input_size, hidden_size=128, num_hidden_layers=2, dropout_rate=0.3):\n        super(ChurnNet, self).__init__()\n        self.layers = nn.ModuleList()\n        self.layers.append(nn.Linear(input_size, hidden_size))\n        for _ in range(num_hidden_layers - 1):\n            self.layers.append(nn.Linear(hidden_size, hidden_size))\n        self.output = nn.Linear(hidden_size, 1)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout_rate)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = self.relu(layer(x))\n            x = self.dropout(x)\n        x = self.sigmoid(self.output(x))\n        return x\n\n# 2. Custom Pytorch Estimator to integrate with the sklearn pipeline\nclass PytorchModel(BaseEstimator, TransformerMixin):\n    def __init__(self, input_size, hidden_size, num_hidden_layers, dropout_rate, lr, num_epochs, batch_size=64):\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_hidden_layers = num_hidden_layers\n        self.dropout_rate = dropout_rate\n        self.lr = lr\n        self.num_epochs = num_epochs\n        self.batch_size = batch_size\n        self.build_model()\n    \n    def build_model(self):\n        layers = []\n        layers.append(nn.Linear(self.input_size, self.hidden_size))  # Adjusted input size\n        layers.append(nn.ReLU())\n        layers.append(nn.Dropout(self.dropout_rate))\n\n        for _ in range(self.num_hidden_layers - 1):\n            layers.append(nn.Linear(self.hidden_size, self.hidden_size))\n            layers.append(nn.ReLU())\n            layers.append(nn.Dropout(self.dropout_rate))\n\n        layers.append(nn.Linear(self.hidden_size, 1))\n        layers.append(nn.Sigmoid())\n        \n        self.model = nn.Sequential(*layers)\n        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n        self.criterion = nn.BCELoss()\n\n    def fit(self, X, y):\n        dataset = TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32))\n        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n\n        for epoch in range(self.num_epochs):\n            self.model.train()\n            running_loss = 0.0\n            for batch_X, batch_y in loader:\n                self.optimizer.zero_grad()\n                outputs = self.model(batch_X)\n                loss = self.criterion(outputs.squeeze(), batch_y)\n                loss.backward()\n                self.optimizer.step()\n                running_loss += loss.item()\n\n            if epoch % 5 == 0:\n                print(f\"Epoch {epoch+1}/{self.num_epochs}, Loss: {running_loss / len(loader):.4f}\")\n\n    def transform(self, X):\n        self.model.eval()\n        with torch.no_grad():\n            outputs = self.model(torch.tensor(X, dtype=torch.float32))\n            return outputs.squeeze().round().numpy()\n\n# 3. Preprocessing steps using ColumnTransformer\npreprocessor = ColumnTransformer(transformers=[\n    ('imputer', SimpleImputer(strategy='median'), X_train.columns),\n    ('scaler', StandardScaler(), X_train.columns)\n])\n\n# 4. SMOTE integration (Modified to accept both X and y during fit_transform)\nclass SMOTETransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.smote = SMOTE(random_state=42)\n\n    def fit(self, X, y):\n        self.X_resampled, self.y_resampled = self.smote.fit_resample(X, y)\n        return self\n\n    def transform(self, X):\n        return self.X_resampled\n\n    def fit_resample(self, X, y):\n        return self.X_resampled, self.y_resampled\n\n    def get_y(self):\n        return self.y_resampled\n\n# 5. Define a custom pipeline to ensure X and y are handled correctly\nclass CustomPipeline(Pipeline):\n    def fit(self, X, y=None, **fit_params):\n        # Extract y after SMOTE and pass it to the model\n        Xt, yt = X, y\n        for name, transform in self.steps[:-1]:\n            Xt = transform.fit_transform(Xt, yt) if name == 'smote' else transform.fit_transform(Xt)\n            if isinstance(transform, SMOTETransformer):\n                yt = transform.get_y()\n        self.steps[-1][-1].fit(Xt, yt)\n        return self\n\n    def predict(self, X):\n        Xt = X\n        for name, transform in self.steps[:-1]:\n            Xt = transform.transform(Xt)\n        return self.steps[-1][-1].transform(Xt)\n\n# 6. Define the full pipeline with preprocessing, SMOTE, and model training\npipeline = CustomPipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('smote', SMOTETransformer()),  # SMOTE for class imbalance handling\n     ('pytorch_model', PytorchModel(input_size=X_train_resampled.shape[1], hidden_size=128, num_hidden_layers=2, dropout_rate=0.3, lr=1e-3, num_epochs=20))\n])\n\n# 7. Train the pipeline\npipeline.fit(X_train_split, y_train_split)\n\n# 8. Evaluate the pipeline on the validation data\ny_val_pred = pipeline.predict(X_val_split)\n\n# 9. Calculate the Matthews Correlation Coefficient (MCC)\nmcc_val_score = matthews_corrcoef(y_val_split, y_val_pred)\nprint(f'Matthews Correlation Coefficient (MCC) on validation data: {mcc_val_score:.4f}')\n\n# 10. Make Predictions on Test Data\ny_test_pred = pipeline.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:00:54.419991Z","iopub.execute_input":"2024-10-22T14:00:54.420763Z","iopub.status.idle":"2024-10-22T14:00:55.079674Z","shell.execute_reply.started":"2024-10-22T14:00:54.420724Z","shell.execute_reply":"2024-10-22T14:00:55.078340Z"},"trusted":true},"execution_count":55,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[55], line 152\u001b[0m\n\u001b[1;32m    145\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m CustomPipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    146\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m    147\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmote\u001b[39m\u001b[38;5;124m'\u001b[39m, SMOTETransformer()),  \u001b[38;5;66;03m# SMOTE for class imbalance handling\u001b[39;00m\n\u001b[1;32m    148\u001b[0m      (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch_model\u001b[39m\u001b[38;5;124m'\u001b[39m, PytorchModel(input_size\u001b[38;5;241m=\u001b[39mX_train_resampled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m))\n\u001b[1;32m    149\u001b[0m ])\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# 7. Train the pipeline\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# 8. Evaluate the pipeline on the validation data\u001b[39;00m\n\u001b[1;32m    155\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_val_split)\n","Cell \u001b[0;32mIn[55], line 135\u001b[0m, in \u001b[0;36mCustomPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, SMOTETransformer):\n\u001b[1;32m    134\u001b[0m         yt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mget_y()\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","Cell \u001b[0;32mIn[55], line 87\u001b[0m, in \u001b[0;36mPytorchModel.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_y \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 87\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), batch_y)\n\u001b[1;32m     89\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x96 and 48x128)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (64x96 and 48x128)","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import matthews_corrcoef\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.utils.validation import check_is_fitted","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:01:35.980209Z","iopub.execute_input":"2024-10-22T14:01:35.981173Z","iopub.status.idle":"2024-10-22T14:01:35.988659Z","shell.execute_reply.started":"2024-10-22T14:01:35.981120Z","shell.execute_reply":"2024-10-22T14:01:35.987619Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"BASE_URL = '/kaggle/input/test-task-for-ds-customer-churn-predict-2024-10/archive'","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:01:37.465944Z","iopub.execute_input":"2024-10-22T14:01:37.466909Z","iopub.status.idle":"2024-10-22T14:01:37.470908Z","shell.execute_reply.started":"2024-10-22T14:01:37.466869Z","shell.execute_reply":"2024-10-22T14:01:37.469875Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Load the data\nX_train = pd.read_csv(f'{BASE_URL}/train.csv')\nX_test = pd.read_csv(f'{BASE_URL}/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:01:38.338085Z","iopub.execute_input":"2024-10-22T14:01:38.338974Z","iopub.status.idle":"2024-10-22T14:01:38.498157Z","shell.execute_reply.started":"2024-10-22T14:01:38.338931Z","shell.execute_reply":"2024-10-22T14:01:38.497307Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Target column\ny = X_train['target_class']","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:01:39.441982Z","iopub.execute_input":"2024-10-22T14:01:39.442857Z","iopub.status.idle":"2024-10-22T14:01:39.447084Z","shell.execute_reply.started":"2024-10-22T14:01:39.442819Z","shell.execute_reply":"2024-10-22T14:01:39.446157Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"X_train.drop('target_class',axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:01:40.441974Z","iopub.execute_input":"2024-10-22T14:01:40.442876Z","iopub.status.idle":"2024-10-22T14:01:40.449326Z","shell.execute_reply.started":"2024-10-22T14:01:40.442836Z","shell.execute_reply":"2024-10-22T14:01:40.448428Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Scaling the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:02:11.998096Z","iopub.execute_input":"2024-10-22T14:02:11.998794Z","iopub.status.idle":"2024-10-22T14:02:12.025000Z","shell.execute_reply.started":"2024-10-22T14:02:11.998756Z","shell.execute_reply":"2024-10-22T14:02:12.024182Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# Handle class imbalance using SMOTE\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:02:13.442324Z","iopub.execute_input":"2024-10-22T14:02:13.443510Z","iopub.status.idle":"2024-10-22T14:02:13.549892Z","shell.execute_reply.started":"2024-10-22T14:02:13.443455Z","shell.execute_reply":"2024-10-22T14:02:13.548841Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Split the training data into train and validation sets\nX_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n    X_train_resampled, y_train_resampled, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:02:14.651520Z","iopub.execute_input":"2024-10-22T14:02:14.651977Z","iopub.status.idle":"2024-10-22T14:02:14.666859Z","shell.execute_reply.started":"2024-10-22T14:02:14.651939Z","shell.execute_reply":"2024-10-22T14:02:14.665920Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Convert to PyTorch tensors\nX_train_tensor = torch.tensor(X_train_split, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train_split.values, dtype=torch.float32)\n\nX_val_tensor = torch.tensor(X_val_split, dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val_split.values, dtype=torch.float32)\n\nX_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:02:15.730706Z","iopub.execute_input":"2024-10-22T14:02:15.731093Z","iopub.status.idle":"2024-10-22T14:02:15.738355Z","shell.execute_reply.started":"2024-10-22T14:02:15.731054Z","shell.execute_reply":"2024-10-22T14:02:15.737454Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# Update the DataLoader for the new training set\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:02:16.770968Z","iopub.execute_input":"2024-10-22T14:02:16.771778Z","iopub.status.idle":"2024-10-22T14:02:16.776357Z","shell.execute_reply.started":"2024-10-22T14:02:16.771737Z","shell.execute_reply":"2024-10-22T14:02:16.775304Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# 2. Define the Neural Network Model\nclass ChurnNet(nn.Module):\n    def __init__(self, input_size):\n        super(ChurnNet, self).__init__()\n        self.fc1 = nn.Linear(input_size, 256)  # Increased to 256 neurons\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 1)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.3)  # Dropout regularization\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.dropout(self.relu(self.fc1(x)))\n        x = self.dropout(self.relu(self.fc2(x)))\n        x = self.sigmoid(self.fc3(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:11:04.654012Z","iopub.execute_input":"2024-10-22T14:11:04.655021Z","iopub.status.idle":"2024-10-22T14:11:04.662565Z","shell.execute_reply.started":"2024-10-22T14:11:04.654977Z","shell.execute_reply":"2024-10-22T14:11:04.661624Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\ninput_size = X_train.shape[1]\nmodel = ChurnNet(input_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:11:05.841148Z","iopub.execute_input":"2024-10-22T14:11:05.842027Z","iopub.status.idle":"2024-10-22T14:11:05.847368Z","shell.execute_reply.started":"2024-10-22T14:11:05.841986Z","shell.execute_reply":"2024-10-22T14:11:05.846566Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# 3. Loss Function and Optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n\n# Learning rate scheduler\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n\nnum_epochs = 50  # Train for more epochs\nbest_mcc = -1\npatience = 10  # Increase patience","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:12:04.746173Z","iopub.execute_input":"2024-10-22T14:12:04.746930Z","iopub.status.idle":"2024-10-22T14:12:04.754391Z","shell.execute_reply.started":"2024-10-22T14:12:04.746888Z","shell.execute_reply":"2024-10-22T14:12:04.752938Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# # 4. Train the Model\n# num_epochs = 20\n# best_mcc = -1  # Initialize best MCC score\n# patience = 5   # Number of epochs to wait for improvement before stopping\n# counter = 0","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:12:05.937287Z","iopub.execute_input":"2024-10-22T14:12:05.937737Z","iopub.status.idle":"2024-10-22T14:12:05.942405Z","shell.execute_reply.started":"2024-10-22T14:12:05.937696Z","shell.execute_reply":"2024-10-22T14:12:05.941244Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for batch_X, batch_y in train_loader:\n        optimizer.zero_grad()\n        outputs = model(batch_X)\n        loss = criterion(outputs.squeeze(), batch_y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n    # Validation phase\n    model.eval()\n    with torch.no_grad():\n        val_preds = model(X_val_tensor).squeeze().round().numpy()\n        mcc_val_score = matthews_corrcoef(y_val_tensor.numpy(), val_preds)\n        print(f'MCC on validation set after epoch {epoch+1}: {mcc_val_score:.4f}')\n\n    if mcc_val_score > best_mcc:\n        best_mcc = mcc_val_score\n        counter = 0\n        torch.save(model.state_dict(), 'best_model.pth')\n    else:\n        counter += 1\n        if counter >= patience:\n            print(f'Early stopping at epoch {epoch+1}')\n            break\n\n    # Step the scheduler\n    scheduler.step(mcc_val_score)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:12:06.918793Z","iopub.execute_input":"2024-10-22T14:12:06.919596Z","iopub.status.idle":"2024-10-22T14:13:11.288195Z","shell.execute_reply.started":"2024-10-22T14:12:06.919556Z","shell.execute_reply":"2024-10-22T14:13:11.287109Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Epoch [1/50], Loss: 0.1823\nMCC on validation set after epoch 1: 0.8583\nEpoch [2/50], Loss: 0.1798\nMCC on validation set after epoch 2: 0.8543\nEpoch [3/50], Loss: 0.1871\nMCC on validation set after epoch 3: 0.8574\nEpoch [4/50], Loss: 0.1786\nMCC on validation set after epoch 4: 0.8591\nEpoch [5/50], Loss: 0.1742\nMCC on validation set after epoch 5: 0.8599\nEpoch [6/50], Loss: 0.1724\nMCC on validation set after epoch 6: 0.8659\nEpoch [7/50], Loss: 0.1726\nMCC on validation set after epoch 7: 0.8724\nEpoch [8/50], Loss: 0.1695\nMCC on validation set after epoch 8: 0.8699\nEpoch [9/50], Loss: 0.1693\nMCC on validation set after epoch 9: 0.8764\nEpoch [10/50], Loss: 0.1662\nMCC on validation set after epoch 10: 0.8786\nEpoch [11/50], Loss: 0.1667\nMCC on validation set after epoch 11: 0.8668\nEpoch [12/50], Loss: 0.1640\nMCC on validation set after epoch 12: 0.8640\nEpoch [13/50], Loss: 0.1661\nMCC on validation set after epoch 13: 0.8732\nEpoch [14/50], Loss: 0.1439\nMCC on validation set after epoch 14: 0.8863\nEpoch [15/50], Loss: 0.1391\nMCC on validation set after epoch 15: 0.8882\nEpoch [16/50], Loss: 0.1377\nMCC on validation set after epoch 16: 0.8930\nEpoch [17/50], Loss: 0.1349\nMCC on validation set after epoch 17: 0.8734\nEpoch [18/50], Loss: 0.1362\nMCC on validation set after epoch 18: 0.8847\nEpoch [19/50], Loss: 0.1333\nMCC on validation set after epoch 19: 0.8909\nEpoch [20/50], Loss: 0.1214\nMCC on validation set after epoch 20: 0.8977\nEpoch [21/50], Loss: 0.1199\nMCC on validation set after epoch 21: 0.8987\nEpoch [22/50], Loss: 0.1195\nMCC on validation set after epoch 22: 0.8872\nEpoch [23/50], Loss: 0.1188\nMCC on validation set after epoch 23: 0.9009\nEpoch [24/50], Loss: 0.1165\nMCC on validation set after epoch 24: 0.8962\nEpoch [25/50], Loss: 0.1156\nMCC on validation set after epoch 25: 0.8926\nEpoch [26/50], Loss: 0.1146\nMCC on validation set after epoch 26: 0.8978\nEpoch [27/50], Loss: 0.1112\nMCC on validation set after epoch 27: 0.9060\nEpoch [28/50], Loss: 0.1081\nMCC on validation set after epoch 28: 0.9056\nEpoch [29/50], Loss: 0.1077\nMCC on validation set after epoch 29: 0.8970\nEpoch [30/50], Loss: 0.1063\nMCC on validation set after epoch 30: 0.9010\nEpoch [31/50], Loss: 0.1071\nMCC on validation set after epoch 31: 0.9053\nEpoch [32/50], Loss: 0.1044\nMCC on validation set after epoch 32: 0.9028\nEpoch [33/50], Loss: 0.1044\nMCC on validation set after epoch 33: 0.9057\nEpoch [34/50], Loss: 0.1012\nMCC on validation set after epoch 34: 0.9062\nEpoch [35/50], Loss: 0.0992\nMCC on validation set after epoch 35: 0.9058\nEpoch [36/50], Loss: 0.0994\nMCC on validation set after epoch 36: 0.9069\nEpoch [37/50], Loss: 0.0994\nMCC on validation set after epoch 37: 0.9073\nEpoch [38/50], Loss: 0.0994\nMCC on validation set after epoch 38: 0.9072\nEpoch [39/50], Loss: 0.1018\nMCC on validation set after epoch 39: 0.9091\nEpoch [40/50], Loss: 0.0986\nMCC on validation set after epoch 40: 0.9058\nEpoch [41/50], Loss: 0.0997\nMCC on validation set after epoch 41: 0.9077\nEpoch [42/50], Loss: 0.1004\nMCC on validation set after epoch 42: 0.9069\nEpoch [43/50], Loss: 0.0995\nMCC on validation set after epoch 43: 0.9075\nEpoch [44/50], Loss: 0.0997\nMCC on validation set after epoch 44: 0.9051\nEpoch [45/50], Loss: 0.0985\nMCC on validation set after epoch 45: 0.9078\nEpoch [46/50], Loss: 0.1008\nMCC on validation set after epoch 46: 0.9071\nEpoch [47/50], Loss: 0.0997\nMCC on validation set after epoch 47: 0.9061\nEpoch [48/50], Loss: 0.0999\nMCC on validation set after epoch 48: 0.9066\nEpoch [49/50], Loss: 0.0984\nMCC on validation set after epoch 49: 0.9073\nEarly stopping at epoch 49\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load('best_model.pth')) \nmodel.eval()\n\nwith torch.no_grad():\n    val_preds = model(X_val_tensor).squeeze().round().numpy()\n    mcc_val_score = matthews_corrcoef(y_val_tensor.numpy(), val_preds)\n    print(f'Best Matthews Correlation Coefficient (MCC) on validation data: {mcc_val_score:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:14:16.181876Z","iopub.execute_input":"2024-10-22T14:14:16.182271Z","iopub.status.idle":"2024-10-22T14:14:16.203855Z","shell.execute_reply.started":"2024-10-22T14:14:16.182232Z","shell.execute_reply":"2024-10-22T14:14:16.202811Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Best Matthews Correlation Coefficient (MCC) on validation data: 0.9091\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/719249595.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_model.pth'))\n","output_type":"stream"}]},{"cell_type":"code","source":"# 6. Make Predictions on Test Data\nwith torch.no_grad():\n    test_preds = model(X_test_tensor).squeeze().round().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:14:35.956157Z","iopub.execute_input":"2024-10-22T14:14:35.956566Z","iopub.status.idle":"2024-10-22T14:14:35.970005Z","shell.execute_reply.started":"2024-10-22T14:14:35.956529Z","shell.execute_reply":"2024-10-22T14:14:35.969062Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"client_ids = X_test.index \nresults = pd.DataFrame({\n    'ID': client_ids,\n    'target': test_preds\n})\nresults.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:14:36.930624Z","iopub.execute_input":"2024-10-22T14:14:36.931313Z","iopub.status.idle":"2024-10-22T14:14:36.947252Z","shell.execute_reply.started":"2024-10-22T14:14:36.931274Z","shell.execute_reply":"2024-10-22T14:14:36.946367Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}